{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialNBClassifier:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha  # Smoothing parameter\n",
    "        self.class_priors = {}\n",
    "        self.feature_probs = {}\n",
    "        self.classes = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        # Calculate class priors and feature likelihoods\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.class_priors[c] = len(X_c) / len(X)\n",
    "            \n",
    "            # Count the occurrences of each feature in the class\n",
    "            feature_counts = X_c.sum(axis=0)\n",
    "            total_count = feature_counts.sum()\n",
    "\n",
    "            # Calculate likelihood with Laplace smoothing\n",
    "            self.feature_probs[c] = (feature_counts + self.alpha) / (total_count + self.alpha * n_features)\n",
    "\n",
    "    def _calculate_posterior(self, x):\n",
    "        posteriors = {}\n",
    "        for c in self.classes:\n",
    "            # Log of the prior for the class\n",
    "            prior = np.log(self.class_priors[c])\n",
    "            # Sum log-likelihoods of features\n",
    "            likelihood = np.sum(x * np.log(self.feature_probs[c]))\n",
    "            posteriors[c] = prior + likelihood\n",
    "        return posteriors\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for x in X:\n",
    "            posteriors = self._calculate_posterior(x)\n",
    "            # Select class with highest posterior\n",
    "            y_pred.append(max(posteriors, key=posteriors.get))\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('full_cleaned_data.csv')\n",
    "data_frame = data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "for entry in data_frame:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract texts and labels\n",
    "texts = data_frame['text']\n",
    "labels = data_frame['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ubah(x):\n",
    "    if x == 'neutral':\n",
    "        return 1\n",
    "    if x == 'negative':\n",
    "        return 0\n",
    "    if x == 'positive':\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'effek kampanye pake sound horeg fufufafa biarin aja turun kelas amin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 2: Convert text to numerical features\u001b[39;00m\n\u001b[0;32m      2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfTransformer()\n\u001b[1;32m----> 3\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Step 3: Split the dataset into training and testing sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1061\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1047\u001b[0m             (\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1057\u001b[0m         )\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1664\u001b[0m, in \u001b[0;36mTfidfTransformer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1646\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Learn the idf vector (global term weights).\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m \n\u001b[0;32m   1648\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[38;5;124;03m    Fitted transformer.\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;66;03m# large sparse data is not supported for 32bit platforms because\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;66;03m# _document_frequency uses np.bincount which works on arrays of\u001b[39;00m\n\u001b[0;32m   1663\u001b[0m \u001b[38;5;66;03m# dtype NPY_INTP which is int32 for 32bit platforms. See #20923\u001b[39;00m\n\u001b[1;32m-> 1664\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_IS_32BIT\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1668\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:951\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    949\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 951\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    955\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1031\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1031\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1033\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'effek kampanye pake sound horeg fufufafa biarin aja turun kelas amin'"
     ]
    }
   ],
   "source": [
    "# Step 2: Convert text to numerical features\n",
    "vectorizer = TfidfTransformer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "X = X.toarray() if hasattr(X, \"toarray\") else X\n",
    "\n",
    "labels = []\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((204, 1555), (204,))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train a Naive Bayes classifier\n",
    "classifier = MultinomialNBClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Make predictions and evaluate the model\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'negative', 'negative', 'negative', 'neutral',\n",
       "       'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'neutral',\n",
       "       'negative', 'negative', 'neutral', 'positive', 'neutral',\n",
       "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative',\n",
       "       'neutral', 'neutral', 'positive', 'negative', 'negative',\n",
       "       'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral',\n",
       "       'positive', 'negative', 'negative', 'neutral', 'negative',\n",
       "       'neutral', 'positive', 'neutral', 'negative', 'positive',\n",
       "       'neutral', 'positive', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       y_pred    y_test\n",
      "228   neutral   neutral\n",
      "6    negative   neutral\n",
      "79    neutral   neutral\n",
      "206  positive   neutral\n",
      "117   neutral  positive\n",
      "185   neutral   neutral\n",
      "242   neutral   neutral\n",
      "167  negative  negative\n",
      "9     neutral  negative\n",
      "30    neutral  negative\n",
      "180  negative   neutral\n",
      "222   neutral   neutral\n",
      "230   neutral  positive\n",
      "217   neutral   neutral\n",
      "136   neutral   neutral\n",
      "68    neutral   neutral\n",
      "199   neutral   neutral\n",
      "15   positive  negative\n",
      "96   negative  negative\n",
      "24    neutral   neutral\n",
      "235  positive  positive\n",
      "19    neutral   neutral\n",
      "120  negative   neutral\n",
      "152   neutral   neutral\n",
      "33    neutral   neutral\n",
      "124  negative   neutral\n",
      "253   neutral   neutral\n",
      "208  negative  negative\n",
      "10    neutral   neutral\n",
      "164   neutral   neutral\n",
      "184   neutral  positive\n",
      "97   negative  negative\n",
      "148   neutral  negative\n",
      "190  negative  negative\n",
      "223   neutral   neutral\n",
      "25    neutral   neutral\n",
      "86   negative   neutral\n",
      "18    neutral  negative\n",
      "75    neutral   neutral\n",
      "137   neutral  positive\n",
      "196  negative  negative\n",
      "176  negative  negative\n",
      "239   neutral   neutral\n",
      "181  negative  negative\n",
      "45    neutral   neutral\n",
      "66   positive  positive\n",
      "16    neutral   neutral\n",
      "67    neutral  negative\n",
      "215  negative  positive\n",
      "201   neutral   neutral\n",
      "177   neutral  positive\n",
      "38   negative   neutral\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({'y_pred': y_pred, 'y_test': y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.53      0.55        15\n",
      "     neutral       0.77      0.70      0.73        33\n",
      "    positive       0.25      0.50      0.33         4\n",
      "\n",
      "    accuracy                           0.63        52\n",
      "   macro avg       0.53      0.58      0.54        52\n",
      "weighted avg       0.67      0.63      0.65        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
